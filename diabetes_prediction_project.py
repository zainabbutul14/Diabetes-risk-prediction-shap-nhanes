# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rvHsxrUcPmwYMgwFfuKRNvmt-dQLHvJ7

# **MY PROJECT WORK FLOW**
"""

# =========================================================
# Project: Diabetes Risk Prediction
# Data: NHANES 2017-2020 Clinical Biomarker Data
# Goal: Build, compare, optimize, and fully interpret models for diabetes prediction
# =========================================================

# --- 1. SETUP: Loading essential tools ---
import pandas as pd
import numpy as np
import warnings
import joblib
import os

# Plotting and Interpretation
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# Machine Learning Libraries
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Metrics
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, confusion_matrix

warnings.filterwarnings("ignore")
sns.set_style("whitegrid")

# ------------------------------------------------------------
# 2. HELPER FUNCTIONS: Key Metrics and Visuals
# ------------------------------------------------------------
def plot_confusion_matrix(cm, labels, name):
    """Visualizes model performance (correct vs. incorrect predictions)."""
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(f'Confusion Matrix - {name}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

def print_metrics(name, y_true, y_pred, y_proba):
    """
    Displays key performance scores (AUC, Sensitivity, Specificity)
    and plots the ROC curve.
    """
    print("--------------------------------------------------")
    print(f"RESULTS FOR: {name} ")
    auc_score = roc_auc_score(y_true, y_proba)
    print(f"ROC-AUC Score: {auc_score:.4f} (Higher is better!)")

    # Calculating Sensitivity & Specificity
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)
    print(f"Sensitivity (Catching Diabetes Cases): {sensitivity:.4f}")
    print(f"Specificity (Correctly Identifying Healthy): {specificity:.4f}")

    print("\nFull Classification Report:")
    print(classification_report(y_true, y_pred, zero_division=0))

    # Plot the ROC curve
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    plt.figure(figsize=(6,5))
    plt.plot(fpr, tpr, label=f"{name} (AUC={auc_score:.3f})")
    plt.plot([0,1],[0,1],"k--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve - {name}")
    plt.legend()
    plt.show()

    return auc_score

# ------------------------------------------------------------
# 3. PHASE I: DATA GATHERING AND CLEANING
# ------------------------------------------------------------
print("PHASE I: Starting data loading and cleaning...")

# Folder with your files
data_folder = "/content/Diabetes prediction project"

# Loading files and merging on SEQN (Patient ID)
file_paths = {
    "demo": os.path.join(data_folder, "P_DEMO 2017-2020.xpt"),
    "glu": os.path.join(data_folder, "P_GLU 2017-2020.xpt"),
    "ins": os.path.join(data_folder, "P_INS 2017-2020.xpt"),
    "ghb": os.path.join(data_folder, "P_GHB 2017-2020.xpt"),
    "bmi": os.path.join(data_folder, "P_BMX 2017-2020.xpt"),
    "diq": os.path.join(data_folder, "P_DIQ 2017-2020.xpt")
}

dfs = {name: pd.read_sas(path, format='xport') for name, path in file_paths.items()}

data = dfs["demo"].merge(dfs["glu"], on="SEQN", how="left")
data = data.merge(dfs["ins"], on="SEQN", how="left")
data = data.merge(dfs["ghb"], on="SEQN", how="left")
data = data.merge(dfs["bmi"], on="SEQN", how="left")
data = data.merge(dfs["diq"], on="SEQN", how="left")

# Rename features for clarity
data = data.rename(columns={
    "LBXGLU": "Glucose", "LBXIN": "Insulin", "LBXGH": "HbA1c",
    "BMXBMI": "BMI", "DIQ010": "Diabetes", "RIDAGEYR": "Age"
})

# Clean Target and handle missing values
data["Diabetes"] = data["Diabetes"].replace({1:1, 2:0, 3:np.nan, 7:np.nan, 9:np.nan})
data = data.dropna(subset=["Diabetes"])
data["Diabetes"] = data["Diabetes"].astype(int)

num_cols = data.select_dtypes(include=[np.number]).columns.tolist()
data[num_cols] = data[num_cols].fillna(data[num_cols].median())

# Outlier removal
data = data[(data["Glucose"] > 20) & (data["Glucose"] < 1000) &
            (data["Insulin"] >=0) & (data["Insulin"] < 2000) &
            (data["BMI"] > 10) & (data["BMI"] < 80)]
print(f"Cleaned data size: {data.shape}")

# ------------------------------------------------------------
# 4. PHASE II: FEATURE ENGINEERING & EDA
# ------------------------------------------------------------
print("\nPHASE II: Creating clinical features and performing EDA...")

# Key feature: HOMA-IR (Insulin Resistance)
data["HOMA_IR"] = (data["Insulin"] * data["Glucose"]) / 405.0
data["Ins_Glu_Ratio"] = np.where(data["Glucose"]>0, data["Insulin"]/data["Glucose"], 0)

features = ["Glucose","Insulin","HbA1c","BMI","Age", "HOMA_IR", "Ins_Glu_Ratio"]
X = data[features]
y = data["Diabetes"]

# EDA: Visualizing top clinical risk factors
top_clinical_features = ["Glucose", "HOMA_IR", "HbA1c"]

plt.figure(figsize=(15, 4))
for i, feature in enumerate(top_clinical_features):
    plt.subplot(1, 3, i + 1)
    sns.histplot(data=data, x=feature, hue="Diabetes", kde=True, palette='coolwarm')
    plt.title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

# ------------------------------------------------------------
# 5. PHASE III: DATA PREP (Splitting & Scaling)
# ------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_test_df = pd.DataFrame(X_test_scaled, columns=features, index=X_test.index)
print("\n--- Data split and scaled. Ready for Model Training! ---")

# ------------------------------------------------------------
# 6. PHASE IV: MODEL TRAINING & COMPARISON
# ------------------------------------------------------------
print("\nPHASE IV: Model Training Shootout! (Comparing 3 Algorithms)")

auc_results = {}

# Logistic Regression
lr = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')
lr.fit(X_train_scaled, y_train)
lr_pred = lr.predict(X_test_scaled)
lr_proba = lr.predict_proba(X_test_scaled)[:,1]
auc_results['Logistic Regression'] = print_metrics("1. Logistic Regression", y_test, lr_pred, lr_proba)

# Random Forest
rf = RandomForestClassifier(random_state=42, n_estimators=150, class_weight="balanced")
rf.fit(X_train_scaled, y_train)
rf_pred = rf.predict(X_test_scaled)
rf_proba = rf.predict_proba(X_test_scaled)[:,1]
auc_results['Random Forest'] = print_metrics("2. Random Forest", y_test, rf_pred, rf_proba)

# XGBoost Baseline
xgb_baseline = XGBClassifier(eval_metric="logloss", use_label_encoder=False, random_state=42, n_estimators=100)
xgb_baseline.fit(X_train_scaled, y_train)
xgb_pred = xgb_baseline.predict(X_test_scaled)
xgb_proba = xgb_baseline.predict_proba(X_test_scaled)[:,1]
auc_results['XGBoost Initial'] = print_metrics("3. XGBoost", y_test, xgb_pred, xgb_proba)

# ------------------------------------------------------------
# 7. PHASE V: OPTIMIZATION & INTERPRETABILITY
# ------------------------------------------------------------
print("\nPHASE V: Hyperparameter Tuning and SHAP Explainability")

param_grid = {"n_estimators":[100, 200], "max_depth":[3, 5], "learning_rate":[0.1, 0.05]}
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

xgb_cv = GridSearchCV(
    XGBClassifier(eval_metric="logloss", use_label_encoder=False, random_state=42),
    param_grid, cv=cv, scoring="roc_auc", n_jobs=-1
)
xgb_cv.fit(X_train_scaled, y_train)

best_xgb_final = xgb_cv.best_estimator_
best_xgb_pred = best_xgb_final.predict(X_test_scaled)
best_xgb_proba = best_xgb_final.predict_proba(X_test_scaled)[:,1]
print("Best XGBoost parameters:", xgb_cv.best_params_)
final_auc = print_metrics("4. XGBoost (FINAL TUNED MODEL)", y_test, best_xgb_pred, best_xgb_proba)
auc_results['XGBoost Final'] = final_auc

# SHAP Explanation
explainer = shap.TreeExplainer(best_xgb_final)
shap_values = explainer.shap_values(X_test_scaled)

# SHAP summary
print("\n--- SHAP Feature Importance Summary ---")
shap.summary_plot(shap_values, X_test_df, show=True)

# Top predictors
mean_abs_shap = np.abs(shap_values).mean(axis=0)
fi = pd.DataFrame({"feature": X_test_df.columns, "mean_abs_shap": mean_abs_shap})
fi_sorted = fi.sort_values("mean_abs_shap", ascending=False)
top_features = fi_sorted.head(5)['feature'].tolist()
print(f"Top 3 most important predictors: **{', '.join(top_features[:3])}**")

# Dependence plot for top predictor
top_feature = top_features[0]
print(f"\n--- Detailed look at {top_feature} ---")
shap.dependence_plot(top_feature, shap_values, X_test_df, interaction_index=None)

# Clinical Takeaways
print("\n--- Clinical Takeaways from SHAP ---")
if "HOMA_IR" in top_features:
    print("1. **Insulin Resistance is Key**: HOMA_IR is crucial in predicting diabetes.")
if "HbA1c" in top_features:
    print("2. **Long-Term Control**: HbA1c strongly contributes to prediction, reflecting chronic glucose exposure.")

# Bar chart for all feature importance
plt.figure(figsize=(8,6))
fi_sorted_bar = fi.sort_values("mean_abs_shap", ascending=True)
plt.barh(fi_sorted_bar['feature'], fi_sorted_bar['mean_abs_shap'], color='teal')
plt.title("Feature Importance (SHAP values)")
plt.xlabel("Mean Absolute SHAP Value")
plt.ylabel("Feature")
plt.show()

# ------------------------------------------------------------
# 8. PHASE VI: CONCLUSION & SAVING ARTIFACTS
# ------------------------------------------------------------
# Ensure the saving directory exists
os.makedirs(data_folder, exist_ok=True)

# Winner model
winner = max(auc_results, key=auc_results.get)
winning_score = auc_results[winner]
baseline_score = auc_results['Logistic Regression']

print("\n=======================================================")
print(f"**CONCLUSION:** The **{winner}** model is the clear winner with ROC-AUC **{winning_score:.4f}**")
print(f"Improvement over Logistic Regression baseline (AUC: {baseline_score:.4f})")
print("=======================================================")

# Saving artifacts in project folder
joblib.dump(best_xgb_final, os.path.join(data_folder, "xgb_final_model.pkl"))
joblib.dump(scaler, os.path.join(data_folder, "scaler_for_deployment.pkl"))
fi.to_csv(os.path.join(data_folder, "feature_importance_shap.csv"), index=False)
print("âœ… All artifacts saved successfully in:", data_folder)

print("\nðŸŽ‰ Project Complete!")